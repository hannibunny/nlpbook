The release of GPT-3 has reinvigorated a discussion of creativity and artificial intelligence. That’s a good discussion to have, primarily because it forces us to think carefully about what we mean when we use words like “creativity” and “art.” As I’ve argued in the past, each time we have this discussion, we end up raising the bar. Each time an AI system does something that looks “intelligent” or creative, we end up deciding that’s not what intelligence really is.  And that’s a good thing. AI is likely to teach us more about what intelligence and creativity are not than about what they are.I’m not terribly interested in whether AI can imitate human creativity. “Can an AI create a ‘new’ poem that reads as if it were written by Keats, or a new piano sonata that sounds like Beethoven” isn’t a question that’s worth asking. Of course it can—if not now, it will be able to in the near future. We really don’t need a new Beethoven sonata; the 32 he wrote are enough. Nor do we need a new Keats ode, limited though his output was. Or a new Rembrandt. Imitation is ultimately a party trick: clever and amusing, but not really important. Sure, if you want texts for greeting cards or elevator music (or maybe even commercial pop), algorithms may do the trick.
      Learn faster. Dig deeper. See farther.
    Join the O'Reilly online learning platform. Get a free trial today and find answers on the fly, or master something new and useful.What’s really important is the transition between different forms of creativity. How do you get something that’s qualitatively new, and not just imitation? Creativity isn’t about the artifacts as much as it’s about the transitions. How do you get from Bach to Haydn? How do you get from Haydn to Beethoven? And, even within the career of a single artist: how do you get from the beginning to the end? How do you get from Beethoven’s first piano sonata, which sounds like Haydn, to the last, which at some points anticipates jazz? Artists aren’t stagnant. But I have no idea how even to ask whether an AI system can “mature” or “grow” in its output.Great artists (and yes, I’m presuming a lot with the word “great”) frequently work by defining themselves against what came before. This is particularly clear with artists of the Romantic period in Germany, England, and France. The term Romanticism didn’t come around until some years later, but they left behind several manifestos describing what they were trying to do, and how it was different from what came before. That is still how artists work: Nnedi Okorafor’s Africanfuturism is important as a way of defining and directing her own work. The importance of these defining statements isn’t so much about “rightness” (in the sense of “this is what art is or should be”) but in setting a direction for their project. Can a machine do that? Can it decide how it work will be different from what came before? It’s not clear to me that it can’t, but that’s a significant step beyond any machine learning projects we currently have.Although artists work by projecting their work into the future, by defining something “new,” their work is also derived from what came before—possibly as misinterpretation, but almost always as revision. Listen to the Beatles, and you hear something that was really built on the backbone of blues, filtered through some British pop-cultural trends. At the end of the “His Dark Materials” trilogy, Phillip Pullman thanks all the authors he stole from. Or, as T. S. Eliot said, “Immature poets imitate; mature poets steal; bad poets deface what they take, and good poets make it into something better, or at least something different.” Artists break from the past by reinterpreting that past.
For AI-generated art–where does that sense of “different” come from? Can artificial intelligence learn to steal and reinterpret? Where does that engagement with history, current events and even selfhood come from?  Without that, there’s no basis for reinterpretation aside from random perturbation. It’s not clear that a sense of history couldn’t come from a big model trained on a gigantic corpus (although the best we can do now is build models that have no idea what they are saying). What kind of model would take that corpus and make something that was different, something that hadn’t been seen before? Would we care if Hamlet wasn’t written by Shakespeare in a specific historical context, but in 2025 by a computer trained on an archive of Elizabethan politics, drama, and history? (Never mind that an archive of Elizabethan drama would be very skimpy; most plays from that period were never published.) Would anyone care about the opera Nixon in China if it didn’t reflect a composer’s, and a librettist’s, thinking about historical events?
There’s another way in which I find computed-generated artworks unsatisfactory, particularly in music. AI-generated music is often interesting over the short term, but fails at larger-scale structure. Much of music history, from four-bar blues to Beethoven’s massive experiments in sonata form, is about building structures that can be interesting over the long term, whether “long term” means a few minutes of a blues song to several hours of opera. That was Beethoven’s project; more recently, it was the project of rock groups like Pink Floyd. It seems conceivable that a model could learn to generate such longer-form structures, but I’ve yet to see one that does it satisfactorily.Is this where collaboration between humans and machines comes in, and if so, what does that say about creativity? A machine could conceivably do the pattern-matching and combinatorics, assembling a creative work out of news clippings and stylistic mimicry. But a human still needs to supply the sense of history that makes the work something we care about. A human still needs to provide the structure that makes art works more than brief curiosities. Is it possible for a human could tweak a model like GPT-3 to give it that sense of direction and context? What kinds of user interfaces would facilitate this kind of interaction?I can’t answer those questions, but that sounds like a much more interesting form of digital collaboration than having an algorithm write hundreds of dull poems or songs and “curating” a few that aren’t boring. That’s just a recipe for greeting-card sentiment and elevator music. I mean no disrespect to Hallmark—mass-produced poetry for greeting cards serves a purpose—but when we think about what kinds of creativity we want, and how that creativity will be mediated by AI, we should demand more.Take O’Reilly online learning with you and learn anywhere, anytime on your phone and tablet.Do not sell my personal informationExercise your consumer rights by contacting us at donotsell@oreilly.com.© 2020, O’Reilly Media, Inc.  All trademarks and registered trademarks appearing on oreilly.com are the property of their respective owners.Terms of service • Privacy policy • Editorial independence