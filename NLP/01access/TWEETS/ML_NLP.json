Advancing NLP with efficient projection-based model architectures https://t.co/riHn8jSYeQ #NLProc
It's not just size that matters: small language models are also few-shot learners https://t.co/at3Ii2R9JE #NLProc
A Comparison of LSTM and BERT for Small Corpus https://t.co/lnbRGKYkVs #NLProc
Language Interpretability Tool (LIT): a visual, interactive model-understanding tool for NLP models https://t.co/NQxNks6Y9O #NLProc
Paraphrase Generation as Zero-Shot Multilingual Translation https://t.co/BegzVJEMGM #NLProc
Word2vec Skip-gram Dimensionality Selection via Sequential Normalized Maximum Likelihood https://t.co/7lxWQUBnnz #NLProc
Large-scale Transfer Learning for Low-resource Spoken Language Understanding https://t.co/HO9gmzsq6a #NLProc
Zero-Shot Learning in Modern NLP https://t.co/UKq8ROLUWG #NLProc
Sentiment Analysis using Deep Learning https://t.co/5RffiRg0T8 #NLProc
Big Bird: Transformers for Longer Sequences https://t.co/l5isSLk0gW #NLProc
Numpy Cheat Sheet https://t.co/yJSWtsm59C #DataScience
GPT-3, a Giant Step for Deep Learning and NLP https://t.co/77iO8LdDoj #NLProc
Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods https://t.co/9KoptxYimk #NLProc
Advances of transformer-based models for news headline generation https://t.co/lSr38lfQRS #NLProc
Generating Stories about Images https://t.co/HB4Vdp2M1y #NLProc
Can we achieve more with less? Exploring data augmentation for toxic comment classification https://t.co/LHBHprGwIo #NLProc
Graph-based, Self-Supervised Program Repair from Diagnostic Feedback https://t.co/aRQJdDPJap #NLProc
Linguistics In NLP: Why So Complex? https://t.co/0BmWbOgO76 #NLProc
Predicting Performance for Natural Language Processing Tasks https://t.co/Mpxb5WBVvp #NLProc
Awesome Vision-Language Navigation: a curated list of research papers in Vision-Language Navigation (VLN)‚Ä¶ https://t.co/jhnCBfWp6K
RT @dirk_hovy: Some things we know bias #NLProc systems:
- data selection
- label schemes
- annotator training
- their incentives
- model o‚Ä¶
NLP vs Filter Bubbles https://t.co/oiNsD92rSL #NLProc
Transformers VS Universal Sentence Encoder https://t.co/jRpXZyQfMn #NLProc
TransCoder: Facebook‚Äôs Unsupervised Programming Language Translator https://t.co/zPAosHRQPE #NLProc
Better &amp; Faster Transformers for Natural Language Processing https://t.co/WIE5ISBjti
End-to-End Adversarial Text-to-Speech https://t.co/G7m54igfmx #NLProc
Running Spark NLP in Docker Container for Named Entity Recognition and Other NLP Features https://t.co/GGQVf5jOGn #NLProc
Machine Learning Classifiers Comparison with Python https://t.co/T45OQ1IKzL #NLProc
Introduction to Deep Similarity Learning for sequences
 https://t.co/TdodCgKSxE #NLProc
The rise of Attention in Neural Networks https://t.co/7BKz9DudTJ #NLProc
Text Classification using Neural Networks https://t.co/YFMzvEKyzp #NLProc
Reinforced Co-Training https://t.co/6kPKHrF8xA #MachineLearning
ConCET: Entity-Aware Topic Classification for Open-Domain Conversational Agents
 https://t.co/a7giZcDc7b #NLProc
GPT-3: Language Models Are Few-Shot Learners https://t.co/eoORzzA5it #NLProc
Turing-NLG: A 17-billion-parameter language model by Microsoft https://t.co/Z3zUvYIa88 #NLProc
Great survey of the state-of-the-art language models https://t.co/yeTflhJfiu #NLProc
Jointly encoding word confusion network and dialogue context with BERT for spoken language understanding https://t.co/fs5qcy0OWM #NLProc
BERTweet: A pre-trained language model for English Tweets https://t.co/NqdI2YEoYU #NLProc
RT @WilliamWangNLP: #NLProc Trends from ACL 2010 - ACL 2019. Super cool visualization of the past decade by Wanxiang Che: https://t.co/7s3P‚Ä¶
Sentiment Analysis in Python with NLTK. 10 Videos ~ 1hour https://t.co/Mio7NE4bRs #NLProc #SentimentAnalysis #Python
[Question] Free software for grammar analysis? https://t.co/HihPdtOgKc
Colab notebook to showcase how to fine-tune T5 on different tasks https://t.co/bKoGJJcl0c #NLProc
RT @gsarti_: #ICLR2020 was full of interesting ideas to improve the Transformer architecture for #NLProc! üí° I summarized and categorized mo‚Ä¶
ContextNet: improving Convolutional Neural Networks for automatic speech recognition with global context https://t.co/AUrxulkkU2 #NLProc
ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformation‚Ä¶ https://t.co/FqqpdNIk6S
How to implement a Word2vec model with NumPy https://t.co/rgQ11XKliz #NLProc
[Feedback Request] Texthero: a Python package for text preprocessing, representation and visualization:‚Ä¶ https://t.co/eYYbCS29IU
Hundreds of NLP notebooks ready to use on Google Colab https://t.co/3e6tiltWW1 #NLProc
10 Top Technical Papers On NLP One Must Read In 2020 https://t.co/bHqj3stw6i #NLProc
RT @johnmccrae: We have released the 2020 edition of English WordNet at https://t.co/oPBMOzgmSC. This version contains ~15,000 changes and‚Ä¶
Solving challenging NLP tasks from just 10-100 examples with pattern-exploiting training (PET) https://t.co/LU0ax9RRVK #NLProc
ToD-BERT: pre-trained Natural Language Understanding for task-oriented dialogues https://t.co/7ZhErCLsGU #NLProc
Are you interested in Machine Learning and NLP? Subscribe and contribute to the Natural Language Processing communi‚Ä¶ https://t.co/ao2P7O32z4
Longformer: a scalable transformer model for long-document NLP tasks without chunking/truncation to fit the 512 lim‚Ä¶ https://t.co/qNOqTH5hpu
Natural Language Processing tutorial for researchers using TensorFlow and Pytorch https://t.co/wn8DVEYzOf #NLProc
Survey results about pre-trained models for Natural Language Processing: https://t.co/rXk5QOPelO #NLProc
Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence https://t.co/QhPtMLyQvH #NLProc
Repository with NLP best practices &amp; examples https://t.co/8pbQBufAM2 #NLProc
Productionizing NLP Models https://t.co/10NslszQLZ #NLProc
[Question] Will trainable word representations in a neural network still produce zero vectors? https://t.co/G2rApP1vnY #NLProc
Tutorials on implementing sequence-to-sequence (seq2seq) models with PyTorch and TorchText https://t.co/4vVlWaZjDz #NLProc
Dataset with over 70 million tweets of #COVID19 for scientific use https://t.co/IWJnd8XMfp #NLProc
RT @CamachoCollados: Given the current situation, @tpilehvar and I have decided to openly release the first draft of our book ‚ÄúEmbeddings i‚Ä¶
Stanza: official Stanford NLP Python library for many human languages https://t.co/JQC94cSYZg #NLProc
Teaching an AI to summarise news articles: A new dataset for abstractive summarisation https://t.co/ZS4VF19Nk3 #NLProc
Browse Scientific Articles about Covid-19 with SciBERT-NLI  https://t.co/q0Gc048Mgi #NLProc
Visualizing Phrase Prominence and Category Association with Scattertext and PyTextRank https://t.co/QYIFmUSTft
Zero-Shot Cross-Lingual Transfer with Meta Learning https://t.co/zyJguKJAM2 #NLProc
SeMemNN: A Semantic Matrix-Based Memory Neural Network for Text Classification https://t.co/OOI1Htnomu #NLProc
Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer https://t.co/HwQEpJCQ86 #NLProc
Label-guided Learning for Text Classification https://t.co/exyegMJeiv #NLProc
Application of Pre-training Models in Named Entity Recognition https://t.co/FnlPpdLAhi #NLProc
Analysis of ML and NLP publication statistics from 2019 https://t.co/ZJAuiPlz8w #NLP #MachineLearning
Rust native BERT implementation https://t.co/8KFF6VrhY7 #NLProc
PEGASUS: Pre-training with Extracted Gap-sentences for
Abstractive Summarization https://t.co/LIhySCEDS4 #NLProc
BERT, ELMo, &amp; GPT-2: How contextual are contextualized word representations? https://t.co/6Bcvpf5FR9 #NLProc
The Attention Mechanism in NLP https://t.co/m6M4HQZLhr #NLProc
A sequence to sequence architecture for task-oriented semantic parsing https://t.co/EDvajmyR4u #NLProc
All kinds of text classification models explained https://t.co/MPTjas6DN7 #NLProc
Exploratory data analysis for Natural Language Processing: guide to Python tools https://t.co/CH6p0v8IqK #NLProc
Transfer learning for speaker verification https://t.co/kHuTxBZhFG #NLProc
PoWER-BERT: Accelerating BERT inference for Classification Tasks https://t.co/LUe2Zy1p0A #NLProc
[Question] Looking for an overview of spectral clustering for documents
https://t.co/ZgepKCWKho #NLProc
The Big Bad NLP Database: datasets for various tasks in Natural Language Processing https://t.co/hqEN2InFr6 #NLProc
User-in-the-loop Adaptive Intent Detection for Instructable Digital Assistant https://t.co/Sl4JQBRhJJ #NLProc
Top NLP Algorithms &amp; Concepts https://t.co/MoLcK2hCO6 #NLProc
Temporal Convolutional Nets (TCNs) take over from RNNs for NLP predictions https://t.co/V59XHC82EA #NLProc
A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning using Py‚Ä¶ https://t.co/p2hkk8Zsgm
Exploratory data analysis for Natural Language Processing https://t.co/IfOR7u5xZZ
Are you interested in Machine Learning and NLP? Subscribe and contribute to the Natural Language Processing communi‚Ä¶ https://t.co/cX5da8AJhk
Simulating Lexical Semantic Change from Sense-Annotated Data https://t.co/oYaeBex5mL #NLProc
Essentials of Deep Learning : Introduction to Long Short Term Memory https://t.co/34AuUdC7rR #NLProc
NLP approaches to data anonymization https://t.co/SROuQ5wI6D #NLProc
NLP Year in Review: 2019 https://t.co/j5UtxXqHfI #NLProc
Simultaneous Identification of Tweet Purpose and Position https://t.co/sSRrt2lsCv #NLPproc
Using Transfer Learning for NLP with Small Data https://t.co/iyFZEIhhUw #NLProc
A Study of Multilingual Neural Machine Translation https://t.co/QFaD9Hz2ct #NLProc
[Question] What are some new interesting trends in document clustering?
 https://t.co/abnfNdVwQK #NLProc
Top NLP Algorithms &amp; Concepts https://t.co/cfcLI5MmrG #NLProc
Application of Word2vec in Phoneme Recognition https://t.co/GbPrC1lCUV #NLProc
Improving Distant Supervised Relation Extraction by Dynamic Neural Network https://t.co/626IdkxdV9 #NLProc
Building a Spam Filter from Scratch Using Machine Learning https://t.co/Pe9nRljGS6 #NLProc
A BERT Baseline for the Natural Questions https://t.co/YLEY0tfjOK #NLProc
Controlling text generation with plug and play language models https://t.co/Wh9fbIl4Dn #NLProc
Scalable Bayesian Preference Learning for Crowds https://t.co/3sRdbPMbTr #NLProc
An Annotated Dataset of Coreference in English Literature https://t.co/vwD9IweeXM #NLProc
Introduction to Bert https://t.co/CNEp0Dqaxu #NLProc
Temporal Convolutional Nets (TCNs) Take Over from RNNs for NLP Predictions https://t.co/V59XHC82EA #NLProc
Deep NLP: Word Vectors with Word2Vec https://t.co/hYD5LoThUC #NLProc
What does a Fine-tuned BERT model look at? https://t.co/JgRzX4zqY9 #NLProc
DialoGPT: Large-scale generative pre-training for conversational response generation https://t.co/NT23vbYMro #NLProc
RT @Smerity: Introducing the SHA-RNN :)
- Read alternative history as a research genre
- Learn of the terrifying tokenization attack that l‚Ä¶
Who did They Respond to? Conversation Structure Modeling using Masked Hierarchical Transformer https://t.co/rLjhFMm3Dg #NLProc
Text classification with extremely small datasets https://t.co/K5oCwkj2nK #NLProc
Aging Memories Generate More Fluent Dialogue Responses with Memory Networks https://t.co/454wknXKCm #NLProc
All The Ways You Can Compress BERT https://t.co/29giEBj6Pl #NLProc
Encoding Database Schemas with Relation-Aware Self-Attention for Text-to-SQL Parsers https://t.co/hD97fMW0MY #NLProc
[Question] Is it possible to use a topic modeling on a small dataset of 250 records? https://t.co/Unn1KNAM4G #NLProc #TopicModeling
Deploy A Text Generating API With Hugging Face‚Äôs DistilGPT-2 https://t.co/MNi6XqXJKw #NLProc
Evaluating the Factual Consistency of Abstractive Text Summarization https://t.co/MKH3mqPEnM #NLProc
Answering Complex Open-domain Questions at Scale https://t.co/e7gvpTw3EM #NLProc
Multiprocessing vs. Threading in Python: What Every Data Scientist Needs to Know https://t.co/MF8r6HCFAS #NLProc
The State of NLP Literature https://t.co/gCtjacdMex #NLProc
A comprehensive guide to Sentiment Analysis https://t.co/7dgoFoP0Mv #NLProc
RT @stanfordnlp: Real-world text NER vs. benchmark dataset NER. #nlproc https://t.co/1Cyw2hJevn
Are you interested in Machine Learning and NLP? Subscribe and contribute to the Natural Language Processing communi‚Ä¶ https://t.co/RnHxXBe35O
Evaluation Metrics for Language Modeling https://t.co/ks522jDDla #NLProc
RT @monkeylearn: What is TF-IDF? https://t.co/Z5tCmD1Fpz
TinyBERT: 7x smaller and 9x faster than BERT but achieves comparable results https://t.co/R9OWavfFPV #NLProc
What causes bias in word embedding associations? https://t.co/zVjDnFXgAp #NLProc
RT @monkeylearn: Introduction to Keyword Extraction https://t.co/YyhVPvHP7W
Must-read Papers on pre-trained language models https://t.co/Oh6UuFOOml #NLProc
Improved Word Sense Disambiguation Using Pre-Trained Contextualized Word Representations https://t.co/I7RgNiOWjE #NLProc
Google‚Äôs ALBERT Is a Leaner BERT; Achieves SOTA on 3 NLP Benchmarks https://t.co/Bo4wwNxYPX #NLProc
A PyTorch implementation of "MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mix‚Ä¶ https://t.co/bWXSfiAFdo
[Discussion] Ideas for master thesis about BERT https://t.co/ku12jh9n4B #NLProc
Extreme language model compression with optimal subwords and shared projections https://t.co/o24oIctgtk #NLProc
A collection of resources to study Transformers in depth https://t.co/WWyCWWJOq3 #NLProc
RT @fchollet: If your classifier is "99% accurate", either you're using the wrong metric (a metric this high is not informative), or you ha‚Ä¶
Understanding BERT Transformer: Attention isn‚Äôt all you need https://t.co/mAmMJCXwXF #NLProc
Developing a Tag Recommendation System for StackOverflow with LDA https://t.co/EIZtBYurql #NLProc
RT @monkeylearn: A comprehensive guide to Topic Analysis https://t.co/KqZzMMUJZF
Enriching BERT with Knowledge Graph Embeddings for Document Classification https://t.co/RYZjKLZJy9 #NLProc
OpenAI fine-tunes GPT-2 for stylistic text generation and summarization https://t.co/o9Ad9ViDwl #NLProc
A PyTorch implementation of "Capsule Graph Neural Network" (ICLR 2019).
 https://t.co/Jgv5mM01pr
Multi-class multilingual classification of Wikipedia articles using extended named entity tag set https://t.co/SkUuTb6Nbj #NLProc
Are you interested in Machine Learning and NLP? Subscribe and contribute to the Natural Language Processing communi‚Ä¶ https://t.co/lSvlNYE59C
The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeli‚Ä¶ https://t.co/wt8k7ZJSa5
Nasty language processing: textual triggers transform bots into bigots
 https://t.co/Tn89ieXaKA #NLProc
RT @rony_armon: If you're using #AI to classify documents or measure text similarity this review should be useful. Many thanks @shaypal5!
V‚Ä¶
New advances in natural language processing to better connect people https://t.co/IPmrmpY43u #NLProc
Conditional Transformer Language Model for Controllable Generation https://t.co/tHmk7t8VQ5 #NLProc #MachineLearning
A repository of community detection (graph clustering) research papers with implementations (deep learning, spectra‚Ä¶ https://t.co/Q0YRSNP9f2
TensorFlow vs PyTorch vs Keras for NLP https://t.co/h2xvib1ktZ #NLProc
SenseBERT: Driving Some Sense into BERT https://t.co/jjzdPtSO4b #NLProc
10 Machine Learning Methods that Every Data Scientist Should Know https://t.co/ivXwiKSAEF #NLProc
Answering Conversational Questions on Structured Data without Logical Forms https://t.co/uF7tW8gVkA #NLProc
Scientific Statement Classification over arXiv https://t.co/T5oT08xiP0 #NLProc
Language Tasks and Language Games: On Methodology in Current Natural Language Processing Research https://t.co/FfxLsfD8jx #NLProc
Introducing FastBert ‚Äî A simple Deep Learning library for BERT Models https://t.co/TvemetHEhJ #NLProc
Distilling BERT Models with spaCy https://t.co/QoUmmitzHs #NLProc
RT @rony_armon: An interesting attempt to use word embeddings to extract information from scientific descriptions using their specific feat‚Ä¶
Text Summarization with Pretrained Encoders https://t.co/XblMuSpEpm #NLProc
SentiMATE: Learning to play Chess through Natural Language Processing https://t.co/DVhmKUuk7D #NLProc
Generating a training corpus for OCR post-correction using encoder-decoder model https://t.co/qkl1kSgcGD #NLProc
Visualizing RNN States with Predictive Semantic Encodings https://t.co/MRYcekDYhu #NLProc
State-of-the-art result for all Machine Learning problems
https://t.co/kp1Y3oLwqa #MachineLearning
What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models https://t.co/R4bQwP6v4k #NLProc
RT @julianharris: Completely pre-train Google BERT from scratch for $USD1 using Google Colab's free TPUs https://t.co/riBXQ2GxWQ
#NLProc (n‚Ä¶
Recommended Stanford online course: Natural Language Processing with Deep Learning https://t.co/WSAca5k0AP #NLProc‚Ä¶ https://t.co/cWYucAo0Ly
Comparison of machine learning techniques in email spam detection https://t.co/jRVe2Y9ouJ #NLProc
How neural networks think? https://t.co/3ARAby6s0q #MachineLearning #DeepLearning
RT @stanfordnlp: Good places for viewing ‚Äúprogress‚Äù in #NLProc‚Äîor at least the latest over-tuning results on various benchmarksüòâ: ‚òÜhttps://‚Ä¶
Adopting Pre-trained BERT for Emotion Classification https://t.co/mteRWsrKy4 #NLProc
Pre-training BERT from scratch with cloud TPU
 https://t.co/rnVGl0KpTP #NLProc
R-Transformer: Recurrent Neural Network Enhanced Transformer https://t.co/GeZoziObL4 #NLProc
Creating WordCloud Using Python
 https://t.co/fV6TVmhh0l
Curated collection of papers for the NLP practitioner üìñüë©‚Äçüî¨ https://t.co/JipNWxixS8 #NLProc
R-Transformer: Recurrent Neural Network Enhanced Transformer https://t.co/GeZoziObL4 #NLProc
A curated list of graph classification methods with implementations (deep learning, graph kernels, embeddings) https://t.co/zXGD5ByO7w
A curated list of gradient boosting research papers with implementations https://t.co/iD0oEaVJnD
NLP vs NLU: from understanding a language to its processing
https://t.co/iXfJW0Js4L #NLProc
Introduction to StanfordNLP: an state-of-the-art NLP library for 53 Languages (with Python code) https://t.co/DcWAuMPtCf #NLProc
How does AI language models and transformers work? https://t.co/B73xZkSIAH #NLProc
[Question] Do you know any kind of Text Mining Feature Taxonomy https://t.co/55A2msFWpS
Summarizing popular Text-to-Image Synthesis methods with Python https://t.co/oqV7sjVfp3 #NLProc
A simple way to explain the Recommendation Engine in AI https://t.co/3foDJRlW02 #NLProc
Embedding projection for targeted cross-lingual sentiment: model comparisons and a real-world study https://t.co/VpjUzGzj6u #NLProc
List of hate speech datasets for NLP https://t.co/Cv6C5WndUr #NLProc
PyCM 2.3 released: Machine learning library for confusion matrix statistical analysis https://t.co/YYnrikgOcN #NLProc
Are you interested in Machine Learning and NLP? Subscribe and contribute to the Natural Language Processing communi‚Ä¶ https://t.co/jyPPjCqVrl
Generative adversarial networks for text generation: non-RL methods https://t.co/tZM9SbMnnm #NLProc
How to train a LSTM Neural Network for text generation https://t.co/E0TDCWPZm1 #NLProc
When and Why does King - Man + Woman = Queen? https://t.co/RJbIevkD1j #NLProc
RT @monkeylearn: How to Implement a Ticket Triaging System with AI https://t.co/orRnkqsHV9
Text classification using Deep Learning and Word2Vec https://t.co/Rhfhe8c0yf #NLProc
XLNet: a new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE)‚Ä¶ https://t.co/T8dPDqz8Rb
[Question] https://t.co/gBvp4WnyMa #NLProc
Informative slides about self-supervised learning from DeepMind https://t.co/Yg8H21MVB3 #MachineLearning
Use of text mining technologies to detect and classify noise complaints from Social Networks https://t.co/8YelePIMu7
